//
//  FaceDetectionVerification.swift
//  MedidorOticaApp
//
//  VerificaÃ§Ã£o 1: DetecÃ§Ã£o de rosto usando ARKit nativo
//  Suporta TrueDepth (cÃ¢mera frontal) e LiDAR (cÃ¢mera traseira)
//

import ARKit
import Vision

// ExtensÃ£o para verificaÃ§Ã£o de detecÃ§Ã£o de rosto
extension VerificationManager {
    
    // MARK: - VerificaÃ§Ã£o 1: DetecÃ§Ã£o de Rosto
    /// Verifica a presenÃ§a de rosto usando o sensor disponÃ­vel e atualiza o estado
    func checkFaceDetection(using frame: ARFrame) -> Bool {
        print("ðŸ” Iniciando verificaÃ§Ã£o de detecÃ§Ã£o de rosto...")
        
        // Verifica qual sensor estÃ¡ disponÃ­vel
        var detected = false
        let sensorType: String
        
        if hasTrueDepth {
            sensorType = "TrueDepth (cÃ¢mera frontal)"
            detected = checkFaceDetectionWithTrueDepth(frame: frame)
        } else if hasLiDAR {
            sensorType = "LiDAR (cÃ¢mera traseira)"
            if #available(iOS 13.4, *) {
                detected = checkFaceDetectionWithLiDAR(frame: frame)
            } else {
                print("âŒ VersÃ£o do iOS muito antiga para usar LiDAR")
            }
        } else {
            let errorMsg = "âŒ ERRO: Nenhum sensor de detecÃ§Ã£o de rosto disponÃ­vel"
            print(errorMsg)
            
            DispatchQueue.main.async { [weak self] in
                guard let self = self else { return }
                
                // Notifica a view sobre a incompatibilidade
                NotificationCenter.default.post(
                    name: NSNotification.Name("DeviceNotCompatible"),
                    object: nil,
                    userInfo: ["reason": "Sensores TrueDepth ou LiDAR nÃ£o encontrados"]
                )
                
                // Atualiza o estado
                if self.faceDetected {
                    print("ðŸ”„ Atualizando estado: rosto nÃ£o detectado (dispositivo incompatÃ­vel)")
                    self.faceDetected = false
                    self.updateAllVerifications()
                }
            }
            return false
        }
        
        print("ðŸ“Š Resultado da detecÃ§Ã£o de rosto: \(detected ? "âœ… Encontrado" : "âŒ NÃ£o encontrado") usando \(sensorType)")
        
        // Atualiza o estado na thread principal apenas se houve mudanÃ§a
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            if self.faceDetected != detected {
                print("ðŸ”„ Atualizando estado de detecÃ§Ã£o de rosto para: \(detected)")
                self.faceDetected = detected
                
                // Se nÃ£o detectou rosto, reseta as outras verificaÃ§Ãµes
                if !detected {
                    self.resetNonFaceVerifications()
                }
                
                self.updateAllVerifications()
            }
        }

        return detected
    }
    
    // MARK: - DetecÃ§Ã£o com TrueDepth (CÃ¢mera Frontal)
    private func checkFaceDetectionWithTrueDepth(frame: ARFrame) -> Bool {
        // Verifica se hÃ¡ um rosto no frame utilizando ARFaceAnchor
        let faceAnchors = frame.anchors.compactMap { $0 as? ARFaceAnchor }
        let hasFace = !faceAnchors.isEmpty
        
        // Se encontrou um rosto, verifica a confianÃ§a do rastreamento
        if hasFace, let faceAnchor = faceAnchors.first {
            let isTracked = faceAnchor.isTracked
            let blendShapes = faceAnchor.blendShapes
            let hasValidBlendShapes = !blendShapes.isEmpty
            
            print("ðŸ‘¤ Rosto detectado usando TrueDepth - " +
                  "Rastreado: \(isTracked ? "âœ…" : "âŒ"), " +
                  "ExpressÃµes: \(hasValidBlendShapes ? "âœ…" : "âŒ")")
            
            // Considera como rosto vÃ¡lido apenas se estiver sendo rastreado e tiver expressÃµes faciais
            return isTracked && hasValidBlendShapes
        } else {
            print("ðŸ” Nenhum rosto detectado com TrueDepth")
            return false
        }
    }
    
    // MARK: - DetecÃ§Ã£o com LiDAR (CÃ¢mera Traseira)
    @available(iOS 13.4, *)
    private func checkFaceDetectionWithLiDAR(frame: ARFrame) -> Bool {
        // Verifica se o frame tem uma imagem capturada
        guard CVPixelBufferGetWidth(frame.capturedImage) > 0 else {
            print("âŒ Frame nÃ£o contÃ©m imagem capturada")
            return false
        }
        
        // Acessa dados de profundidade do LiDAR
        guard let depthData = frame.sceneDepth ?? frame.smoothedSceneDepth else {
            print("âŒ Dados de profundidade do LiDAR nÃ£o disponÃ­veis")
            return false
        }
        
        // ObtÃ©m o depth map para anÃ¡lise
        let depthMap = depthData.depthMap
        let width = CVPixelBufferGetWidth(depthMap)
        let height = CVPixelBufferGetHeight(depthMap)
        
        // Configura a detecÃ§Ã£o de rosto usando Vision
        let request = VNDetectFaceRectanglesRequest()
        let handler = VNImageRequestHandler(
            cvPixelBuffer: frame.capturedImage,
            orientation: .right,
            options: [:])
        
        do {
            try handler.perform([request])

            // Verifica se detectou rostos
            if let results = request.results, !results.isEmpty {
                for faceObservation in results {
                    // Converte as coordenadas normalizadas para coordenadas de pixel
                    let boundingBox = faceObservation.boundingBox
                    let centerX = boundingBox.midX * CGFloat(width)
                    let centerY = (1 - boundingBox.midY) * CGFloat(height) // Inverte Y para coordenadas da imagem
                    
                    // ObtÃ©m valores de profundidade para vÃ¡rios pontos do rosto
                    var depthValues: [Float] = []
                    
                    // Amostra 5 pontos no rosto para maior precisÃ£o
                    let samplePoints = [
                        CGPoint(x: centerX, y: centerY), // Centro
                        CGPoint(x: centerX - boundingBox.width * 0.25, y: centerY), // Esquerda
                        CGPoint(x: centerX + boundingBox.width * 0.25, y: centerY), // Direita
                        CGPoint(x: centerX, y: centerY - boundingBox.height * 0.25), // Cima
                        CGPoint(x: centerX, y: centerY + boundingBox.height * 0.25)  // Baixo
                    ]
                    
                    // Coleta profundidades para os pontos de amostra
                    for point in samplePoints {
                        if let depth = depthValue(from: depthMap, at: point) {
                            depthValues.append(depth)
                        }
                    }
                    
                    // Se temos pelo menos 3 valores vÃ¡lidos de profundidade
                    if depthValues.count >= 3 {
                        // Calcula a mÃ©dia das profundidades
                        let avgDepth = depthValues.reduce(0, +) / Float(depthValues.count)
                        
                        // Verifica se a profundidade estÃ¡ em um intervalo vÃ¡lido para um rosto
                        // TÃ­picamente, rostos estÃ£o entre 0.3m e 1.5m da cÃ¢mera
                        if avgDepth > 0.3 && avgDepth < 1.5 {
                            print("Rosto detectado usando LiDAR a \(String(format: "%.2f", avgDepth))m")
                            return true
                        }
                    }
                }
            }
            
            print("ðŸ” Nenhum rosto detectado com LiDAR - Nenhuma face encontrada na imagem")
            return false
            
        } catch {
            print("ERRO na detecÃ§Ã£o de rosto com LiDAR: \(error)")
            return false
        }
    }
    
}
