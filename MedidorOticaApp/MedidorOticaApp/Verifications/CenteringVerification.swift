//
//  CenteringVerification.swift
//  MedidorOticaApp
//
//  Verifica√ß√£o de Centraliza√ß√£o do Rosto
//
//  Objetivo:
//  - Garantir que o rosto esteja perfeitamente centralizado na c√¢mera
//  - Posicionar o dispositivo no meio do nariz, na altura das pupilas
//  - Fornecer feedback visual sobre o posicionamento
//
//  Crit√©rios de Aceita√ß√£o:
//  1. Centraliza√ß√£o horizontal (eixo X) com margem de ¬±0,5cm
//  2. Centraliza√ß√£o vertical (eixo Y) com margem de ¬±0,5cm
//  3. Alinhamento do nariz com o centro da c√¢mera
//
//  T√©cnicas Utilizadas:
//  - ARKit Face Tracking para detec√ß√£o precisa de pontos faciais
//  - C√°lculos 3D para determinar o posicionamento relativo
//  - Toler√¢ncia ajust√°vel para diferentes cen√°rios de uso
//
//  Notas de Desempenho:
//  - Processamento otimizado para execu√ß√£o em tempo real
//  - Uso eficiente de mem√≥ria com reutiliza√ß√£o de estruturas
//  - C√°lculos otimizados para evitar sobrecarga na CPU/GPU

import ARKit
import Vision
import simd

// MARK: - Extens√µes

extension Notification.Name {
    /// Notifica√ß√£o enviada quando o status de centraliza√ß√£o do rosto √© atualizado
    static let faceCenteringUpdated = Notification.Name("faceCenteringUpdated")
}

// MARK: - Extens√£o para verifica√ß√£o de centraliza√ß√£o
extension VerificationManager {
    
    // MARK: - Constantes
    
    private enum CenteringConstants {
        // Toler√¢ncia de 0,5 cm convertida para metros
        static let tolerance: Float = 0.005

        // √çndice do v√©rtice correspondente √† ponta do nariz
        struct FaceIndices {
            static let noseTip = 9
        }
    }

    /// Medidas calculadas para orientar o ajuste da c√¢mera em rela√ß√£o ao PC
    private struct FaceCenteringMetrics {
        let horizontal: Float
        let vertical: Float
        let noseAlignment: Float
    }
    
    // MARK: - Verifica√ß√£o de Centraliza√ß√£o
    
    /// Verifica se o rosto est√° corretamente centralizado na c√¢mera
    /// - Parameters:
    ///   - frame: O frame AR atual (n√£o utilizado, mantido para compatibilidade)
    ///   - faceAnchor: O anchor do rosto detectado pelo ARKit
    /// - Returns: Booleano indicando se o rosto est√° perfeitamente centralizado
    /// Confere se o rosto est√° centralizado
    func checkFaceCentering(using frame: ARFrame, faceAnchor: ARFaceAnchor?) -> Bool {
        let sensors = preferredSensors(requireFaceAnchor: true, faceAnchorAvailable: faceAnchor != nil)

        guard !sensors.isEmpty else { return false }

        for sensor in sensors {
            switch sensor {
            case .trueDepth:
                guard let anchor = faceAnchor else { continue }
                return checkCenteringWithTrueDepth(faceAnchor: anchor, frame: frame)
            case .liDAR:
                return checkCenteringWithLiDAR(frame: frame)
            case .none:
                continue
            }
        }

        return false
    }

    private func checkCenteringWithTrueDepth(faceAnchor: ARFaceAnchor, frame: ARFrame) -> Bool {
        // Obt√©m a geometria 3D do rosto
        let vertices = faceAnchor.geometry.vertices

        // Valida se temos v√©rtices suficientes para an√°lise
        guard vertices.count > CenteringConstants.FaceIndices.noseTip else {
            print("‚ùå Geometria facial incompleta para an√°lise de centraliza√ß√£o")
            return false
        }

        // Converte pontos faciais para o sistema de coordenadas da c√¢mera
        let worldToCamera = simd_inverse(frame.camera.transform)
        let leftEyeWorld = simd_mul(faceAnchor.transform, faceAnchor.leftEyeTransform)
        let rightEyeWorld = simd_mul(faceAnchor.transform, faceAnchor.rightEyeTransform)
        let noseWorld = simd_mul(faceAnchor.transform,
                                 simd_float4(vertices[CenteringConstants.FaceIndices.noseTip], 1))
        let leftEyeCam = simd_mul(worldToCamera, leftEyeWorld)
        let rightEyeCam = simd_mul(worldToCamera, rightEyeWorld)
        let noseCam = simd_mul(worldToCamera, noseWorld)

        // Calcula o ponto central (PC) usando a altura m√©dia das pupilas e o eixo X do nariz
        let averageEyeHeight = (leftEyeCam.columns.3.y + rightEyeCam.columns.3.y) / 2
        let horizontalOffset = noseCam.x
        let verticalOffset = averageEyeHeight

        // Consolida todas as medidas para avaliar e exibir na interface
        let metrics = FaceCenteringMetrics(
            horizontal: horizontalOffset,
            vertical: verticalOffset,
            noseAlignment: noseCam.x
        )

        return evaluateCentering(using: metrics)
    }

    private func checkCenteringWithLiDAR(frame: ARFrame) -> Bool {
        guard let depthMap = frame.sceneDepth?.depthMap ?? frame.smoothedSceneDepth?.depthMap else {
            print("‚ùå Dados de profundidade LiDAR n√£o dispon√≠veis")
            return false
        }

        let request = makeLandmarksRequest()
        let handler = VNImageRequestHandler(
            cvPixelBuffer: frame.capturedImage,
            orientation: currentCGOrientation(),
            options: [:]
        )
        do {
            try handler.perform([request])
            guard let face = request.results?.first as? VNFaceObservation,
                  let landmarks = face.landmarks else { return false }

            let width = CVPixelBufferGetWidth(depthMap)
            let height = CVPixelBufferGetHeight(depthMap)
            let nosePointNorm = landmarks.nose?.normalizedPoints.first ?? CGPoint(x: face.boundingBox.midX, y: face.boundingBox.midY)
            let leftEyeCenter = averagePoint(from: landmarks.leftEye?.normalizedPoints ?? [])
            let rightEyeCenter = averagePoint(from: landmarks.rightEye?.normalizedPoints ?? [])
            let eyeCenterY = (leftEyeCenter.y + rightEyeCenter.y) / 2

            let px = nosePointNorm.x * CGFloat(width)
            let py = (1 - nosePointNorm.y) * CGFloat(height)
            guard let depth = depthValue(from: depthMap, at: CGPoint(x: px, y: py)) else { return false }

            let leftEyeDepthPoint = CGPoint(x: (leftEyeCenter.x) * CGFloat(width),
                                            y: (1 - leftEyeCenter.y) * CGFloat(height))
            let rightEyeDepthPoint = CGPoint(x: (rightEyeCenter.x) * CGFloat(width),
                                             y: (1 - rightEyeCenter.y) * CGFloat(height))
            guard let leftEyeDepth = depthValue(from: depthMap, at: leftEyeDepthPoint),
                  let rightEyeDepth = depthValue(from: depthMap, at: rightEyeDepthPoint) else {
                return false
            }

            // Profundidade m√©dia dos olhos para estimar a altura do PC em metros
            let averageEyeDepth = (leftEyeDepth + rightEyeDepth) / 2
            let horizontalOffset = Float(nosePointNorm.x - 0.5) * depth
            let verticalOffset = Float(0.5 - eyeCenterY) * averageEyeDepth

            let metrics = FaceCenteringMetrics(
                horizontal: horizontalOffset,
                vertical: verticalOffset,
                noseAlignment: horizontalOffset
            )

            return evaluateCentering(using: metrics)
        } catch {
            print("Erro ao verificar centraliza√ß√£o com Vision: \(error)")
            return false
        }
    }

    // MARK: - Avalia√ß√£o de m√©tricas

    /// Avalia se o rosto est√° centralizado com base nas m√©tricas calculadas
    private func evaluateCentering(using metrics: FaceCenteringMetrics) -> Bool {
        // Verifica se os desvios est√£o dentro da toler√¢ncia permitida
        let isHorizontallyAligned = abs(metrics.horizontal) < CenteringConstants.tolerance
        let isVerticallyAligned = abs(metrics.vertical) < CenteringConstants.tolerance
        let isNoseAligned = abs(metrics.noseAlignment) < CenteringConstants.tolerance

        // Resultado global
        let isCentered = isHorizontallyAligned && isVerticallyAligned && isNoseAligned

        // Atualiza a interface com os valores reais, sem compensa√ß√µes fixas
        updateCenteringUI(
            horizontalOffset: metrics.horizontal,
            verticalOffset: metrics.vertical,
            noseOffset: metrics.noseAlignment,
            isCentered: isCentered
        )

        return isCentered
    }
    
    // MARK: - Atualiza√ß√£o da Interface
    
    /// Atualiza a interface do usu√°rio com os resultados da verifica√ß√£o de centraliza√ß√£o
    private func updateCenteringUI(horizontalOffset: Float, verticalOffset: Float, 
                                 noseOffset: Float, isCentered: Bool) {
        // Converte as medidas para cent√≠metros para exibi√ß√£o
        let horizontalCm = horizontalOffset * 100
        let verticalCm = verticalOffset * 100
        let noseCm = noseOffset * 100
        
        // Log detalhado para debug
        print("""
        üìè Centraliza√ß√£o (cm):
           - Horizontal: \(String(format: "%+.2f", horizontalCm)) cm
           - Vertical:   \(String(format: "%+.2f", verticalCm)) cm
           - Nariz:      \(String(format: "%+.2f", noseCm)) cm
           - Alinhado:   \(isCentered ? "‚úÖ" : "‚ùå")
        """)
        
        // Atualiza a interface na thread principal
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }

            // Armazena os desvios para feedback visual
            self.facePosition = [
                "x": horizontalCm,
                "y": verticalCm,
                "z": noseCm
            ]
            
            // Notifica a interface sobre a atualiza√ß√£o
            self.notifyCenteringUpdate()
        }
    }
    
    /// Notifica a interface sobre a atualiza√ß√£o do status de centraliza√ß√£o
    private func notifyCenteringUpdate() {
        NotificationCenter.default.post(
            name: .faceCenteringUpdated,
            object: nil,
            userInfo: [
                "isCentered": faceAligned,
                "offsets": facePosition,
                "timestamp": Date().timeIntervalSince1970
            ]
        )
    }
}
