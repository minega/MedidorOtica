//
//  CenteringVerification.swift
//  MedidorOticaApp
//
//  Verifica√ß√£o de Centraliza√ß√£o do Rosto
//
//  Objetivo:
//  - Garantir que o rosto esteja perfeitamente centralizado na c√¢mera
//  - Posicionar o dispositivo no meio do nariz, na altura das pupilas
//  - Fornecer feedback visual sobre o posicionamento
//
//  Crit√©rios de Aceita√ß√£o:
//  1. Centraliza√ß√£o horizontal (eixo X) com margem de ¬±0,5cm
//  2. Centraliza√ß√£o vertical (eixo Y) com margem de ¬±0,5cm
//  3. Alinhamento do nariz com o centro da c√¢mera
//
//  T√©cnicas Utilizadas:
//  - ARKit Face Tracking para detec√ß√£o precisa de pontos faciais
//  - C√°lculos 3D para determinar o posicionamento relativo
//  - Toler√¢ncia ajust√°vel para diferentes cen√°rios de uso
//
//  Notas de Desempenho:
//  - Processamento otimizado para execu√ß√£o em tempo real
//  - Uso eficiente de mem√≥ria com reutiliza√ß√£o de estruturas
//  - C√°lculos otimizados para evitar sobrecarga na CPU/GPU

import ARKit
import Vision
import simd
import UIKit

// MARK: - Extens√µes

extension Notification.Name {
    /// Notifica√ß√£o enviada quando o status de centraliza√ß√£o do rosto √© atualizado
    static let faceCenteringUpdated = Notification.Name("faceCenteringUpdated")
}

// MARK: - Extens√£o para verifica√ß√£o de centraliza√ß√£o
extension VerificationManager {
    
    // MARK: - Constantes
    
    private enum CenteringConstants {
        // Toler√¢ncia de 0,5 cm convertida para metros
        static let tolerance: Float = 0.005

        // √çndice do v√©rtice correspondente √† ponta do nariz
        struct FaceIndices {
            static let noseTip = 9
        }
    }

    /// Medidas calculadas para orientar o ajuste da c√¢mera em rela√ß√£o ao PC
    private struct FaceCenteringMetrics {
        let horizontal: Float
        let vertical: Float
        let noseAlignment: Float
    }
    
    // MARK: - Verifica√ß√£o de Centraliza√ß√£o
    
    /// Verifica se o rosto est√° corretamente centralizado na c√¢mera
    /// - Parameters:
    ///   - frame: O frame AR atual (n√£o utilizado, mantido para compatibilidade)
    ///   - faceAnchor: O anchor do rosto detectado pelo ARKit
    /// - Returns: Booleano indicando se o rosto est√° perfeitamente centralizado
    /// Confere se o rosto est√° centralizado
    func checkFaceCentering(using frame: ARFrame, faceAnchor: ARFaceAnchor?) -> Bool {
        let sensors = preferredSensors(requireFaceAnchor: true, faceAnchorAvailable: faceAnchor != nil)

        guard !sensors.isEmpty else { return false }

        for sensor in sensors {
            switch sensor {
            case .trueDepth:
                guard let anchor = faceAnchor else { continue }
                return checkCenteringWithTrueDepth(faceAnchor: anchor, frame: frame)
            case .liDAR:
                return checkCenteringWithLiDAR(frame: frame)
            case .none:
                continue
            }
        }

        return false
    }

    private func checkCenteringWithTrueDepth(faceAnchor: ARFaceAnchor, frame: ARFrame) -> Bool {
        guard let metrics = makeAlignedTrueDepthMetrics(faceAnchor: faceAnchor, frame: frame) else {
            print("‚ùå N√£o foi poss√≠vel calcular m√©tricas de centraliza√ß√£o v√°lidas")
            return false
        }

        return evaluateCentering(using: metrics)
    }

    /// Calcula m√©tricas de centraliza√ß√£o em metros compensando o deslocamento da lente TrueDepth na tela.
    private func makeAlignedTrueDepthMetrics(faceAnchor: ARFaceAnchor, frame: ARFrame) -> FaceCenteringMetrics? {
        let vertices = faceAnchor.geometry.vertices

        guard vertices.count > CenteringConstants.FaceIndices.noseTip else {
            return nil
        }

        let worldToCamera = simd_inverse(frame.camera.transform)
        let leftEyeWorld = simd_mul(faceAnchor.transform, faceAnchor.leftEyeTransform)
        let rightEyeWorld = simd_mul(faceAnchor.transform, faceAnchor.rightEyeTransform)
        let noseWorld = simd_mul(faceAnchor.transform,
                                 simd_float4(vertices[CenteringConstants.FaceIndices.noseTip], 1))
        let leftEyeCam = simd_mul(worldToCamera, leftEyeWorld)
        let rightEyeCam = simd_mul(worldToCamera, rightEyeWorld)
        let noseCam = simd_mul(worldToCamera, noseWorld)

        let noseDepth = abs(noseCam.z)
        let leftEyeDepth = abs(leftEyeCam.columns.3.z)
        let rightEyeDepth = abs(rightEyeCam.columns.3.z)
        let averageEyeHeight = (leftEyeCam.columns.3.y + rightEyeCam.columns.3.y) / 2
        let averageEyeDepth = max(0.01, (leftEyeDepth + rightEyeDepth) / 2)

        guard noseDepth > 0.01 else { return nil }

        let viewportSize = currentViewportSize()
        let lensPoint = cameraLensPoint(in: viewportSize)
        let orientation = currentUIOrientation()

        guard let coefficients = alignmentCoefficients(for: frame,
                                                       targetPoint: lensPoint,
                                                       viewportSize: viewportSize,
                                                       orientation: orientation) else {
            print("‚ö†Ô∏è Falha ao alinhar com a posi√ß√£o real da c√¢mera, usando valores brutos")
            return FaceCenteringMetrics(horizontal: noseCam.x,
                                        vertical: averageEyeHeight,
                                        noseAlignment: noseCam.x)
        }

        let horizontalOffset = noseCam.x - Float(coefficients.horizontal) * noseDepth
        let verticalOffset = averageEyeHeight - Float(coefficients.vertical) * averageEyeDepth

        return FaceCenteringMetrics(horizontal: horizontalOffset,
                                    vertical: verticalOffset,
                                    noseAlignment: horizontalOffset)
    }

    /// Obt√©m os coeficientes que convertem deslocamentos da tela para o espa√ßo da c√¢mera.
    private func alignmentCoefficients(for frame: ARFrame,
                                       targetPoint: CGPoint,
                                       viewportSize: CGSize,
                                       orientation: UIInterfaceOrientation) -> (horizontal: Double, vertical: Double)? {
        guard viewportSize.width > 0, viewportSize.height > 0 else { return nil }

        let displayTransform = frame.displayTransform(for: orientation, viewportSize: viewportSize)
        let viewToImage = displayTransform.inverted()
        let normalizedViewport = CGPoint(x: targetPoint.x / viewportSize.width,
                                         y: targetPoint.y / viewportSize.height)
        let normalizedImage = normalizedViewport.applying(viewToImage)

        guard normalizedImage.x.isFinite, normalizedImage.y.isFinite else { return nil }

        let resolution = frame.camera.imageResolution
        let pixelX = Double(normalizedImage.x) * Double(resolution.width)
        let pixelY = Double(normalizedImage.y) * Double(resolution.height)

        let intrinsics = frame.camera.intrinsics
        let fx = Double(intrinsics.columns.0.x)
        let fy = Double(intrinsics.columns.1.y)
        let cx = Double(intrinsics.columns.2.x)
        let cy = Double(intrinsics.columns.2.y)

        guard fx > 0, fy > 0 else { return nil }

        let horizontal = (pixelX - cx) / fx
        let vertical = (pixelY - cy) / fy

        guard horizontal.isFinite, vertical.isFinite else { return nil }

        return (horizontal: horizontal, vertical: vertical)
    }

    /// Retorna o tamanho atual do viewport utilizado para renderizar a c√¢mera.
    private func currentViewportSize() -> CGSize {
        if Thread.isMainThread {
            return UIScreen.main.bounds.size
        }

        var size = CGSize.zero
        DispatchQueue.main.sync {
            size = UIScreen.main.bounds.size
        }
        return size
    }

    /// Calcula a posi√ß√£o aproximada da lente TrueDepth na tela para alinhar o PC.
    private func cameraLensPoint(in viewportSize: CGSize) -> CGPoint {
        let insets = keyWindowSafeAreaInsets()
        let topInset = max(insets.top, 44)
        let isDynamicIsland = topInset > 47
        let xOffset: CGFloat = isDynamicIsland ? 40 : 0
        let x = viewportSize.width / 2 + xOffset
        let y = max(0, topInset - 14)
        return CGPoint(x: x, y: y)
    }

    /// Obt√©m os `safeAreaInsets` da janela principal de forma thread-safe.
    private func keyWindowSafeAreaInsets() -> UIEdgeInsets {
        let fetchInsets: () -> UIEdgeInsets = {
            UIApplication.shared.connectedScenes
                .compactMap { $0 as? UIWindowScene }
                .flatMap { $0.windows }
                .first { $0.isKeyWindow }?.safeAreaInsets ?? .zero
        }

        if Thread.isMainThread {
            return fetchInsets()
        }

        var insets = UIEdgeInsets.zero
        DispatchQueue.main.sync {
            insets = fetchInsets()
        }
        return insets
    }

    private func checkCenteringWithLiDAR(frame: ARFrame) -> Bool {
        guard let depthMap = frame.sceneDepth?.depthMap ?? frame.smoothedSceneDepth?.depthMap else {
            print("‚ùå Dados de profundidade LiDAR n√£o dispon√≠veis")
            return false
        }

        let request = makeLandmarksRequest()
        let handler = VNImageRequestHandler(
            cvPixelBuffer: frame.capturedImage,
            orientation: currentCGOrientation(),
            options: [:]
        )
        do {
            try handler.perform([request])
            guard let face = request.results?.first as? VNFaceObservation,
                  let landmarks = face.landmarks else { return false }

            let width = CVPixelBufferGetWidth(depthMap)
            let height = CVPixelBufferGetHeight(depthMap)
            let nosePointNorm = landmarks.nose?.normalizedPoints.first ?? CGPoint(x: face.boundingBox.midX, y: face.boundingBox.midY)
            let leftEyeCenter = averagePoint(from: landmarks.leftEye?.normalizedPoints ?? [])
            let rightEyeCenter = averagePoint(from: landmarks.rightEye?.normalizedPoints ?? [])
            let eyeCenterY = (leftEyeCenter.y + rightEyeCenter.y) / 2

            let px = nosePointNorm.x * CGFloat(width)
            let py = (1 - nosePointNorm.y) * CGFloat(height)
            guard let depth = depthValue(from: depthMap, at: CGPoint(x: px, y: py)) else { return false }

            let leftEyeDepthPoint = CGPoint(x: (leftEyeCenter.x) * CGFloat(width),
                                            y: (1 - leftEyeCenter.y) * CGFloat(height))
            let rightEyeDepthPoint = CGPoint(x: (rightEyeCenter.x) * CGFloat(width),
                                             y: (1 - rightEyeCenter.y) * CGFloat(height))
            guard let leftEyeDepth = depthValue(from: depthMap, at: leftEyeDepthPoint),
                  let rightEyeDepth = depthValue(from: depthMap, at: rightEyeDepthPoint) else {
                return false
            }

            // Profundidade m√©dia dos olhos para estimar a altura do PC em metros
            let averageEyeDepth = (leftEyeDepth + rightEyeDepth) / 2
            let horizontalOffset = Float(nosePointNorm.x - 0.5) * depth
            let verticalOffset = Float(0.5 - eyeCenterY) * averageEyeDepth

            let metrics = FaceCenteringMetrics(
                horizontal: horizontalOffset,
                vertical: verticalOffset,
                noseAlignment: horizontalOffset
            )

            return evaluateCentering(using: metrics)
        } catch {
            print("Erro ao verificar centraliza√ß√£o com Vision: \(error)")
            return false
        }
    }

    // MARK: - Avalia√ß√£o de m√©tricas

    /// Avalia se o rosto est√° centralizado com base nas m√©tricas calculadas
    private func evaluateCentering(using metrics: FaceCenteringMetrics) -> Bool {
        // Verifica se os desvios est√£o dentro da toler√¢ncia permitida
        let isHorizontallyAligned = abs(metrics.horizontal) < CenteringConstants.tolerance
        let isVerticallyAligned = abs(metrics.vertical) < CenteringConstants.tolerance
        let isNoseAligned = abs(metrics.noseAlignment) < CenteringConstants.tolerance

        // Resultado global
        let isCentered = isHorizontallyAligned && isVerticallyAligned && isNoseAligned

        // Atualiza a interface com os valores reais, sem compensa√ß√µes fixas
        updateCenteringUI(
            horizontalOffset: metrics.horizontal,
            verticalOffset: metrics.vertical,
            noseOffset: metrics.noseAlignment,
            isCentered: isCentered
        )

        return isCentered
    }
    
    // MARK: - Atualiza√ß√£o da Interface
    
    /// Atualiza a interface do usu√°rio com os resultados da verifica√ß√£o de centraliza√ß√£o
    private func updateCenteringUI(horizontalOffset: Float, verticalOffset: Float, 
                                 noseOffset: Float, isCentered: Bool) {
        // Converte as medidas para cent√≠metros para exibi√ß√£o
        let horizontalCm = horizontalOffset * 100
        let verticalCm = verticalOffset * 100
        let noseCm = noseOffset * 100
        
        // Log detalhado para debug
        print("""
        üìè Centraliza√ß√£o (cm):
           - Horizontal: \(String(format: "%+.2f", horizontalCm)) cm
           - Vertical:   \(String(format: "%+.2f", verticalCm)) cm
           - Nariz:      \(String(format: "%+.2f", noseCm)) cm
           - Alinhado:   \(isCentered ? "‚úÖ" : "‚ùå")
        """)
        
        // Atualiza a interface na thread principal
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }

            // Armazena os desvios para feedback visual
            self.facePosition = [
                "x": horizontalCm,
                "y": verticalCm,
                "z": noseCm
            ]
            
            // Notifica a interface sobre a atualiza√ß√£o
            self.notifyCenteringUpdate()
        }
    }
    
    /// Notifica a interface sobre a atualiza√ß√£o do status de centraliza√ß√£o
    private func notifyCenteringUpdate() {
        NotificationCenter.default.post(
            name: .faceCenteringUpdated,
            object: nil,
            userInfo: [
                "isCentered": faceAligned,
                "offsets": facePosition,
                "timestamp": Date().timeIntervalSince1970
            ]
        )
    }
}
