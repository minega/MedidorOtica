//
//  CenteringVerification.swift
//  MedidorOticaApp
//
//  Verifica√ß√£o de Centraliza√ß√£o do Rosto
//
//  Objetivo:
//  - Garantir que o rosto esteja perfeitamente centralizado na c√¢mera
//  - Posicionar o dispositivo no meio do nariz, na altura das pupilas
//  - Fornecer feedback visual sobre o posicionamento
//
//  Crit√©rios de Aceita√ß√£o:
//  1. Centraliza√ß√£o horizontal (eixo X) com margem de ¬±0,5cm
//  2. Centraliza√ß√£o vertical (eixo Y) com margem de ¬±0,5cm
//  3. Alinhamento do nariz com o centro da c√¢mera
//
//  T√©cnicas Utilizadas:
//  - ARKit Face Tracking para detec√ß√£o precisa de pontos faciais
//  - C√°lculos 3D para determinar o posicionamento relativo
//  - Toler√¢ncia ajust√°vel para diferentes cen√°rios de uso
//
//  Notas de Desempenho:
//  - Processamento otimizado para execu√ß√£o em tempo real
//  - Uso eficiente de mem√≥ria com reutiliza√ß√£o de estruturas
//  - C√°lculos otimizados para evitar sobrecarga na CPU/GPU

import Foundation
import ARKit
import Vision
import simd
import CoreGraphics

// MARK: - Extens√µes

extension Notification.Name {
    /// Notifica√ß√£o enviada quando o status de centraliza√ß√£o do rosto √© atualizado
    static let faceCenteringUpdated = Notification.Name("faceCenteringUpdated")
}

// MARK: - Extens√£o para verifica√ß√£o de centraliza√ß√£o
extension VerificationManager {
    
    // MARK: - Constantes
    
    private enum CenteringConstants {
        // Toler√¢ncia de 0,5 cm convertida para metros
        static let tolerance: Float = 0.005

        // √çndice do v√©rtice correspondente √† ponta do nariz
        struct FaceIndices {
            static let noseTip = 9
        }
    }

    /// Medidas calculadas para orientar o ajuste da c√¢mera em rela√ß√£o ao PC
    private struct FaceCenteringMetrics {
        let horizontal: Float
        let vertical: Float
        let noseAlignment: Float
    }
    
    // MARK: - Verifica√ß√£o de Centraliza√ß√£o
    
    /// Verifica se o rosto est√° corretamente centralizado na c√¢mera
    /// - Parameters:
    ///   - frame: O frame AR atual (n√£o utilizado, mantido para compatibilidade)
    ///   - faceAnchor: O anchor do rosto detectado pelo ARKit
    /// - Returns: Booleano indicando se o rosto est√° perfeitamente centralizado
    /// Confere se o rosto est√° centralizado
    func checkFaceCentering(using frame: ARFrame, faceAnchor: ARFaceAnchor?) -> Bool {
        let sensors = preferredSensors(requireFaceAnchor: true, faceAnchorAvailable: faceAnchor != nil)

        guard !sensors.isEmpty else { return false }

        for sensor in sensors {
            switch sensor {
            case .trueDepth:
                guard let anchor = faceAnchor else { continue }
                return checkCenteringWithTrueDepth(faceAnchor: anchor, frame: frame)
            case .liDAR:
                return checkCenteringWithLiDAR(frame: frame)
            case .none:
                continue
            }
        }

        return false
    }

    private func checkCenteringWithTrueDepth(faceAnchor: ARFaceAnchor, frame: ARFrame) -> Bool {
        guard let metrics = makeAlignedTrueDepthMetrics(faceAnchor: faceAnchor, frame: frame) else {
            print("‚ùå N√£o foi poss√≠vel calcular m√©tricas de centraliza√ß√£o v√°lidas")
            return false
        }

        return evaluateCentering(using: metrics)
    }

    /// Calcula m√©tricas de centraliza√ß√£o em metros compensando o deslocamento da lente TrueDepth na tela.
    private func makeAlignedTrueDepthMetrics(faceAnchor: ARFaceAnchor, frame: ARFrame) -> FaceCenteringMetrics? {
        let vertices = faceAnchor.geometry.vertices

        guard vertices.count > CenteringConstants.FaceIndices.noseTip else {
            return nil
        }

        // Obt√©m a transforma√ß√£o do rosto diretamente no espa√ßo da c√¢mera para eliminar
        // discrep√¢ncias de tela/lente e usar a posi√ß√£o f√≠sica real do sensor.
        let worldToCamera = simd_inverse(frame.camera.transform)
        let faceInCamera = simd_mul(worldToCamera, faceAnchor.transform)

        // Converte os principais pontos faciais para coordenadas da c√¢mera (em metros).
        guard let nosePosition = positionFromHomogeneous(
            simd_mul(faceInCamera, simd_float4(vertices[CenteringConstants.FaceIndices.noseTip], 1))
        ) else {
            return nil
        }

        // O centro da face no espa√ßo da c√¢mera representa a posi√ß√£o ideal que deve coincidir com a origem.
        let faceCenter = translation(from: faceInCamera)

        let leftEyeTransform = simd_mul(faceInCamera, faceAnchor.leftEyeTransform)
        let rightEyeTransform = simd_mul(faceInCamera, faceAnchor.rightEyeTransform)

        let leftEyePosition = translation(from: leftEyeTransform)
        let rightEyePosition = translation(from: rightEyeTransform)

        // Altura da pupila calculada pela m√©dia das posi√ß√µes das duas pupilas no espa√ßo da c√¢mera.
        let eyeCenter = (leftEyePosition + rightEyePosition) / 2

        // Calcula o centro do nariz em rela√ß√£o ao centro m√©dio das pupilas para evitar vi√©s lateral.
        let eyesCenterX = (leftEyePosition.x + rightEyePosition.x) / 2
        let noseAlignmentOffset = nosePosition.x - eyesCenterX

        return FaceCenteringMetrics(horizontal: faceCenter.x,
                                    vertical: faceCenter.y,
                                    noseAlignment: noseAlignmentOffset)
    }

    private func checkCenteringWithLiDAR(frame: ARFrame) -> Bool {
        guard let depthMap = frame.sceneDepth?.depthMap ?? frame.smoothedSceneDepth?.depthMap else {
            print("‚ùå Dados de profundidade LiDAR n√£o dispon√≠veis")
            return false
        }

        let request = makeLandmarksRequest()
        let handler = VNImageRequestHandler(
            cvPixelBuffer: frame.capturedImage,
            orientation: currentCGOrientation(),
            options: [:]
        )
        do {
            try handler.perform([request])
            guard let face = request.results?.first as? VNFaceObservation,
                  let landmarks = face.landmarks else { return false }

            let orientation = currentCGOrientation()
            let (depthWidth, depthHeight) = orientedDimensions(for: depthMap, orientation: orientation)
            let resolution = frame.camera.imageResolution
            let intrinsics = frame.camera.intrinsics

            // Calcula pontos m√©dios para nariz e pupilas nas orienta√ß√µes da c√¢mera e do depth map.
            let nosePoints = resolvedLandmarkPoints(from: landmarks.nose?.normalizedPoints,
                                                    boundingBox: face.boundingBox,
                                                    imageWidth: Int(resolution.width),
                                                    imageHeight: Int(resolution.height),
                                                    orientation: orientation)
                ?? fallbackResolvedPoint(at: CGPoint(x: face.boundingBox.midX, y: face.boundingBox.midY),
                                         imageWidth: Int(resolution.width),
                                         imageHeight: Int(resolution.height),
                                         orientation: orientation)

            let leftEyePoints = resolvedLandmarkPoints(from: landmarks.leftEye?.normalizedPoints,
                                                       boundingBox: face.boundingBox,
                                                       imageWidth: Int(resolution.width),
                                                       imageHeight: Int(resolution.height),
                                                       orientation: orientation)

            let rightEyePoints = resolvedLandmarkPoints(from: landmarks.rightEye?.normalizedPoints,
                                                        boundingBox: face.boundingBox,
                                                        imageWidth: Int(resolution.width),
                                                        imageHeight: Int(resolution.height),
                                                        orientation: orientation)

            guard let leftEyePoints, let rightEyePoints else { return false }

            // Amostragem de profundidade usando a grade do depth map j√° orientada.
            guard let noseDepth = depthValue(from: depthMap,
                                             at: depthPixel(from: nosePoints.depth,
                                                            width: depthWidth,
                                                            height: depthHeight)),
                  let leftEyeDepth = depthValue(from: depthMap,
                                                at: depthPixel(from: leftEyePoints.depth,
                                                               width: depthWidth,
                                                               height: depthHeight)),
                  let rightEyeDepth = depthValue(from: depthMap,
                                                 at: depthPixel(from: rightEyePoints.depth,
                                                                width: depthWidth,
                                                                height: depthHeight)) else {
                return false
            }

            let noseCamera = cameraCoordinates(from: nosePoints.camera,
                                               depth: noseDepth,
                                               resolution: resolution,
                                               intrinsics: intrinsics)
            let leftEyeCamera = cameraCoordinates(from: leftEyePoints.camera,
                                                  depth: leftEyeDepth,
                                                  resolution: resolution,
                                                  intrinsics: intrinsics)
            let rightEyeCamera = cameraCoordinates(from: rightEyePoints.camera,
                                                   depth: rightEyeDepth,
                                                   resolution: resolution,
                                                   intrinsics: intrinsics)

            guard let noseCamera,
                  let leftEyeCamera,
                  let rightEyeCamera else {
                return false
            }

            let eyesCenter = (leftEyeCamera + rightEyeCamera) / 2
            let noseAlignmentOffset = noseCamera.x - (leftEyeCamera.x + rightEyeCamera.x) / 2

            let metrics = FaceCenteringMetrics(
                horizontal: eyesCenter.x,
                vertical: eyesCenter.y,
                noseAlignment: noseAlignmentOffset
            )

            return evaluateCentering(using: metrics)
        } catch {
            print("Erro ao verificar centraliza√ß√£o com Vision: \(error)")
            return false
        }
    }

    /// Calcula pontos m√©dios convertidos para o espa√ßo da c√¢mera e para o depth map.
    private func resolvedLandmarkPoints(from points: [CGPoint]?,
                                        boundingBox: CGRect,
                                        imageWidth: Int,
                                        imageHeight: Int,
                                        orientation: CGImagePropertyOrientation) -> (camera: CGPoint, depth: CGPoint)? {
        guard let points, !points.isEmpty else { return nil }

        var accumulator = CGPoint.zero
        for point in points {
            accumulator.x += point.x
            accumulator.y += point.y
        }

        let average = CGPoint(x: accumulator.x / CGFloat(points.count),
                               y: accumulator.y / CGFloat(points.count))
        return fallbackResolvedPoint(at: CGPoint(x: boundingBox.origin.x + average.x * boundingBox.width,
                                                 y: boundingBox.origin.y + average.y * boundingBox.height),
                                     imageWidth: imageWidth,
                                     imageHeight: imageHeight,
                                     orientation: orientation)
    }

    /// Converte um ponto normalizado gen√©rico para coordenadas utilizadas pelo depth map e pela c√¢mera.
    private func fallbackResolvedPoint(at normalizedPoint: CGPoint,
                                       imageWidth: Int,
                                       imageHeight: Int,
                                       orientation: CGImagePropertyOrientation) -> (camera: CGPoint, depth: CGPoint) {
        let pixelPoint = VNImagePointForNormalizedPoint(normalizedPoint,
                                                        imageWidth,
                                                        imageHeight)
        let rawCameraNormalized = CGPoint(x: pixelPoint.x / CGFloat(imageWidth),
                                          y: pixelPoint.y / CGFloat(imageHeight))
        let cameraNormalized = clampedNormalizedPoint(rawCameraNormalized)
        let depthNormalized = self.normalizedPoint(pixelPoint,
                                                  width: imageWidth,
                                                  height: imageHeight,
                                                  orientation: orientation)
        return (camera: cameraNormalized, depth: depthNormalized)
    }

    // MARK: - Avalia√ß√£o de m√©tricas

    /// Avalia se o rosto est√° centralizado com base nas m√©tricas calculadas
    private func evaluateCentering(using metrics: FaceCenteringMetrics) -> Bool {
        // Verifica se os desvios est√£o dentro da toler√¢ncia permitida
        let isHorizontallyAligned = abs(metrics.horizontal) < CenteringConstants.tolerance
        let isVerticallyAligned = abs(metrics.vertical) < CenteringConstants.tolerance
        let isNoseAligned = abs(metrics.noseAlignment) < CenteringConstants.tolerance

        // Resultado global
        let isCentered = isHorizontallyAligned && isVerticallyAligned && isNoseAligned

        // Atualiza a interface com os valores reais, sem compensa√ß√µes fixas
        updateCenteringUI(
            horizontalOffset: metrics.horizontal,
            verticalOffset: metrics.vertical,
            noseOffset: metrics.noseAlignment,
            isCentered: isCentered
        )

        return isCentered
    }

    // MARK: - Atualiza√ß√£o da Interface
    
    /// Atualiza a interface do usu√°rio com os resultados da verifica√ß√£o de centraliza√ß√£o
    private func updateCenteringUI(horizontalOffset: Float, verticalOffset: Float,
                                 noseOffset: Float, isCentered: Bool) {
        // Converte as medidas para cent√≠metros para exibi√ß√£o
        let horizontalCm = horizontalOffset * 100
        let verticalCm = verticalOffset * 100
        let noseCm = noseOffset * 100
        
        // Log detalhado para debug
        print("""
        üìè Centraliza√ß√£o (cm):
           - Horizontal: \(String(format: "%+.2f", horizontalCm)) cm
           - Vertical:   \(String(format: "%+.2f", verticalCm)) cm
           - Nariz:      \(String(format: "%+.2f", noseCm)) cm
           - Alinhado:   \(isCentered ? "‚úÖ" : "‚ùå")
        """)
        
        // Atualiza a interface na thread principal
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }

            // Armazena o status atualizado para sincronizar com a notifica√ß√£o disparada
            self.faceAligned = isCentered

            // Armazena os desvios para feedback visual
            self.facePosition = [
                "x": horizontalCm,
                "y": verticalCm,
                "z": noseCm
            ]

            // Notifica a interface sobre a atualiza√ß√£o
            self.notifyCenteringUpdate(isCentered: isCentered)
        }
    }

    /// Notifica a interface sobre a atualiza√ß√£o do status de centraliza√ß√£o
    private func notifyCenteringUpdate(isCentered: Bool) {
        NotificationCenter.default.post(
            name: .faceCenteringUpdated,
            object: nil,
            userInfo: [
                "isCentered": isCentered,
                "offsets": facePosition,
                "timestamp": Date().timeIntervalSince1970
            ]
        )
    }
}

// MARK: - Conversores auxiliares

private extension VerificationManager {
    /// Converte um vetor homog√™neo em coordenadas 3D usuais.
    func positionFromHomogeneous(_ vector: simd_float4) -> SIMD3<Float>? {
        guard vector.w.isFinite, abs(vector.w) > Float.ulpOfOne else { return nil }
        return SIMD3<Float>(vector.x / vector.w,
                            vector.y / vector.w,
                            vector.z / vector.w)
    }

    /// Extrai o componente de transla√ß√£o de uma matriz 4x4.
    func translation(from transform: simd_float4x4) -> SIMD3<Float> {
        let translation = transform.columns.3
        return SIMD3<Float>(translation.x, translation.y, translation.z)
    }

    /// Converte um ponto normalizado (0...1) e sua profundidade em coordenadas da c√¢mera.
    func cameraCoordinates(from normalizedPoint: CGPoint,
                           depth: Float,
                           resolution: CGSize,
                           intrinsics: simd_float3x3) -> SIMD3<Float>? {
        guard depth.isFinite, depth > 0 else { return nil }

        let fx = intrinsics.columns.0.x
        let fy = intrinsics.columns.1.y
        let cx = intrinsics.columns.2.x
        let cy = intrinsics.columns.2.y

        guard fx > 0, fy > 0 else { return nil }

        let pixelX = Float(normalizedPoint.x) * Float(resolution.width)
        let pixelY = Float(normalizedPoint.y) * Float(resolution.height)

        let x = (pixelX - cx) / fx * depth
        let y = (pixelY - cy) / fy * depth

        return SIMD3<Float>(x, y, depth)
    }

    /// Converte um ponto normalizado em coordenadas de pixel considerando orienta√ß√£o da depth map.
    func depthPixel(from normalizedPoint: CGPoint, width: Int, height: Int) -> CGPoint {
        CGPoint(x: normalizedPoint.x * CGFloat(width),
                y: normalizedPoint.y * CGFloat(height))
    }
}
